{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation & transformation\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalise((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "# Getting the data\n",
    "trainset = datasets.MNIST(path, download=True, train=True, transform=transform)\n",
    "#trainset = datasets.FashionMNIST(path, download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)# Dataloader\n",
    "\n",
    "testset = datasets.MNIST(path, download=True, train=False, transform=transform)\n",
    "#testset = datasets.FashionMNIST(path, download=True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=True)# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "# Define network architecture\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(p=0.2),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) # Define our optimizer\n",
    "\n",
    "# Data\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1) # Flatten\n",
    "\n",
    "# Forward pass\n",
    "logits = model.forward(images)\n",
    "loss = criterion(logits, labels) # Calculate loss\n",
    "\n",
    "loss.backward() # Calculate the Gradients for each layer\n",
    "\n",
    "optimizer.step() # Taking 1 step and update the weights\n",
    "\n",
    "\n",
    "# Calculating accuracy on test data\n",
    "images, labels = next(iter(testloader))\n",
    "images = images.view(images.shape[0], -1) # Flatten\n",
    "\n",
    "# switch off gradients to save computation cost\n",
    "with torch.no_grad():\n",
    "    # model.eval() # if using dropout layers\n",
    "    logits = model.forward(images)\n",
    "    top_prob, top_class = logits.topk(1, dim=1) # Calculating the top probability and predicted class\n",
    "    equals = top_class == labels.view(*top_class.shape) # if the class equals the labels\n",
    "    torch.mean(equals.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a loop to train\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1) # Flatten\n",
    "        \n",
    "        output = model.forward(images) # Forward pass\n",
    "        loss = criterion(output, labels) # calculate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss.backward() # Calculate gradients\n",
    "        \n",
    "        optimizer.step() # Update weights\n",
    "        optimizer.zero_grad() # zero out gradients\n",
    "        \n",
    "    print(f\"Training loss: {running_loss/len(trainloader)}\")s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "class Simple_Network(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden1 = nn.Linear(input_size, 128)\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        \n",
    "        self.output = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
